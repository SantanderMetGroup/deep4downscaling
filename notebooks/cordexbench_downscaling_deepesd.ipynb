{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7daedd7b-217f-4cbf-8689-dc1c91ae88ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import sys; sys.path.append('/home/jovyan/work/deep4downscaling')\n",
    "import deep4downscaling.viz\n",
    "import deep4downscaling.trans\n",
    "import deep4downscaling.deep.loss\n",
    "import deep4downscaling.deep.utils\n",
    "import deep4downscaling.deep.models\n",
    "import deep4downscaling.deep.train\n",
    "import deep4downscaling.deep.pred\n",
    "import deep4downscaling.metrics\n",
    "import deep4downscaling.metrics_ccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b35406c9-81a3-42a4-bd7f-b7ba2f4d83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the domain to downscale\n",
    "domain = 'ALPS' # (ALPS, NZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254632af-fb3a-479e-b4eb-cba6e0948d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "DATA_PATH = f'./data/CORDEXBench/{domain}/{domain}_domain'\n",
    "FIGURES_PATH = f'./figures/CORDEXBench/{domain}'\n",
    "MODELS_PATH = f'./models/CORDEXBench/{domain}'\n",
    "\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "os.makedirs(FIGURES_PATH, exist_ok=True)\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec9263b-bcbc-4a4e-a5a0-5e99aebc1188",
   "metadata": {},
   "source": [
    "### CORDEXBench Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c348bf25-76db-4e99-9e7c-94b6239a3195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-04 09:47:18--  https://zenodo.org/records/15797226/files/ALPS_domain.zip?download=1\n",
      "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.45.92, 188.185.48.194, ...\n",
      "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3620287187 (3.4G) [application/octet-stream]\n",
      "Saving to: ‘./data/CORDEXBench/ALPS/ALPS_domain.zip?download=1’\n",
      "\n",
      "ALPS_domain.zip?dow 100%[===================>]   3.37G  15.4MB/s    in 2m 23s  \n",
      "\n",
      "2025-07-04 09:49:41 (24.2 MB/s) - ‘./data/CORDEXBench/ALPS/ALPS_domain.zip?download=1’ saved [3620287187/3620287187]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "if domain == 'ALPS':\n",
    "    !wget -P ./data/CORDEXBench/ALPS https://zenodo.org/records/15797226/files/ALPS_domain.zip?download=1\n",
    "    !mv ./data/CORDEXBench/ALPS/ALPS_domain.zip* ./data/CORDEXBench/ALPS/ALPS_domain.zip \n",
    "    \n",
    "    with zipfile.ZipFile('./data/CORDEXBench/ALPS/ALPS_domain.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./data/CORDEXBench/ALPS')\n",
    "    \n",
    "    !rm ./data/CORDEXBench/ALPS/ALPS_domain.zip \n",
    "    \n",
    "elif domain == 'NZ':\n",
    "    raise ValueError('TODO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470099c3-abf4-43d7-b3ca-248abca6393e",
   "metadata": {},
   "source": [
    "### Training Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0475a7b5-15ba-4203-9245-182b84e0c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the experiment for training the model\n",
    "training_experiment = 'ESD_pseudo_reality' # (ESD-pseudo-reality, Emulator_hist_fut)\n",
    "gcm_name = 'CNRM-CM5'\n",
    "\n",
    "# Set the period\n",
    "if training_experiment == 'ESD_pseudo_reality':\n",
    "    period_training = '1961-1980'\n",
    "elif training_experiment == 'Emulator_hist_fut':\n",
    "    period_training = '1961-1980_2080-2099'\n",
    "else:\n",
    "    raise ValueError('Provide a valid date')\n",
    "\n",
    "# Set the target variable\n",
    "target_var = 'tasmax' # (tasmax, pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a9d8bb6-4937-49ad-a894-6df0419cbc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 112MB\n",
      "Dimensions:  (time: 7305, lat: 16, lon: 16)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 58kB 1961-01-01T12:00:00 ... 1980-12-31T12...\n",
      "  * lon      (lon) float64 128B -4.0 -2.0 0.0 2.0 4.0 ... 20.0 22.0 24.0 26.0\n",
      "  * lat      (lat) float64 128B 32.0 34.0 36.0 38.0 40.0 ... 56.0 58.0 60.0 62.0\n",
      "Data variables: (12/15)\n",
      "    u_850    (time, lat, lon) float32 7MB ...\n",
      "    u_700    (time, lat, lon) float32 7MB ...\n",
      "    u_500    (time, lat, lon) float32 7MB ...\n",
      "    v_850    (time, lat, lon) float32 7MB ...\n",
      "    v_700    (time, lat, lon) float32 7MB ...\n",
      "    v_500    (time, lat, lon) float32 7MB ...\n",
      "    ...       ...\n",
      "    t_850    (time, lat, lon) float32 7MB ...\n",
      "    t_700    (time, lat, lon) float32 7MB ...\n",
      "    t_500    (time, lat, lon) float32 7MB ...\n",
      "    z_850    (time, lat, lon) float32 7MB ...\n",
      "    z_700    (time, lat, lon) float32 7MB ...\n",
      "    z_500    (time, lat, lon) float32 7MB ...\n",
      "Attributes: (12/28)\n",
      "    CDI:                            Climate Data Interface version 2.4.4 (htt...\n",
      "    Conventions:                    CF-1.6\n",
      "    institution:                    CNRM (Centre National de Recherches Meteo...\n",
      "    description:                    Created by xios\n",
      "    title:                          Created by xios\n",
      "    creation_date:                  2020-03-01T12:29:46Z\n",
      "    ...                             ...\n",
      "    driving_experiment_comment:     Known issue correction: this simulation (...\n",
      "    frequency:                      day\n",
      "    tracking_id:                    hdl:21.14103/73d0f2aa-dfec-4e02-955f-b707...\n",
      "    comment:                        CORDEX Europe EUR-11 CNRM-ALADIN 6.3 L91 ...\n",
      "    history:                        Fri Jun 27 04:41:41 2025: cdo remap,/gpfs...\n",
      "    CDO:                            Climate Data Operators version 2.4.4 (htt...\n"
     ]
    }
   ],
   "source": [
    "# Load predictors\n",
    "predictor_filename = f'{DATA_PATH}/train/{training_experiment}/predictors/{gcm_name}_{period_training}.nc'\n",
    "predictor = xr.open_dataset(predictor_filename)\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b843ede-1388-410a-9ada-1ef0e21ad5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predictors\n",
    "deep4downscaling.viz.multiple_map_plot(data=predictor.mean('time'),\n",
    "                                       output_path=f'./{FIGURES_PATH}/predictor_climatology_{training_experiment}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5fe9800-ae6b-4dbb-a611-db0f4c6e0f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 479MB\n",
      "Dimensions:  (time: 7305, y: 128, x: 128)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 58kB 1961-01-01T12:00:00 ... 1980-12-31T12...\n",
      "    lon      (y, x) float64 131kB ...\n",
      "    lat      (y, x) float64 131kB ...\n",
      "  * x        (x) float64 1kB 2.062e+03 2.075e+03 ... 3.638e+03 3.65e+03\n",
      "  * y        (y) float64 1kB 1.412e+03 1.425e+03 1.438e+03 ... 2.988e+03 3e+03\n",
      "Data variables:\n",
      "    tasmax   (time, y, x) float32 479MB ...\n",
      "Attributes: (12/26)\n",
      "    description:                    Created by xios\n",
      "    title:                          Created by xios\n",
      "    Conventions:                    CF-1.6\n",
      "    creation_date:                  2018-10-24T11:26:47Z\n",
      "    name:                           EUR-11_CNRM-CERFACS-CNRM-CM5_historical_r...\n",
      "    institute_id:                   CNRM\n",
      "    ...                             ...\n",
      "    references:                     http://www.umr-cnrm.fr/spip.php?article12...\n",
      "    comment:                        CORDEX Europe EUR-11 CNRM-ALADIN 6.3 L91 ...\n",
      "    c3s_disclaimer:                 This data has been produced in the contex...\n",
      "    driving_experiment_comment:     Known issue correction: this simulation (...\n",
      "    frequency:                      day\n",
      "    tracking_id:                    hdl:21.14103/e0344943-4520-4786-94f8-4cbf...\n"
     ]
    }
   ],
   "source": [
    "# Load predictand\n",
    "predictand_filename = f'{DATA_PATH}/train/{training_experiment}/target/pr_tasmax_{gcm_name}_{period_training}.nc'\n",
    "predictand = xr.open_dataset(predictand_filename)\n",
    "predictand = predictand[[target_var]] # Univariate\n",
    "print(predictand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b22b0ffb-8c37-4204-81d9-43e43389b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictand\n",
    "deep4downscaling.viz.simple_map_plot(data=predictand.isel(time=100),\n",
    "                                     colorbar='hot_r', var_to_plot=target_var,\n",
    "                                     output_path=f'./{FIGURES_PATH}/predictand_day_{training_experiment}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7711e216-1302-4bcf-b6af-5f7dae2443f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no observations containing null values\n"
     ]
    }
   ],
   "source": [
    "# Remove days with nans in the predictor\n",
    "predictor = deep4downscaling.trans.remove_days_with_nans(predictor)\n",
    "\n",
    "# Align both datasets in time\n",
    "predictor, predictand = deep4downscaling.trans.align_datasets(predictor, predictand, 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a3d3d2e-ded8-4d2d-93cf-b2a5211bdc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selec training and test periods\n",
    "if training_experiment == 'ESD_pseudo_reality':\n",
    "    years_train = list(range(1961, 1975))\n",
    "    years_test = list(range(1975, 1980+1))\n",
    "elif training_experiment == 'Emulator_hist_fut':\n",
    "    years_train = list(range(1961, 1980+1)) + list(range(2080, 2090))\n",
    "    years_test = list(range(2090, 2099+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e3fcbc8-365d-4b8c-bbbc-8d4ee88b1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subet into training and test sets\n",
    "x_train = predictor.sel(time=np.isin(predictor['time'].dt.year, years_train))\n",
    "y_train = predictand.sel(time=np.isin(predictand['time'].dt.year, years_train))\n",
    "\n",
    "x_test = predictor.sel(time=np.isin(predictor['time'].dt.year, years_test))\n",
    "y_test = predictand.sel(time=np.isin(predictand['time'].dt.year, years_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "126affa4-b763-414f-8e06-679aa2e72c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the predictor\n",
    "x_train_stand = deep4downscaling.trans.standardize(data_ref=x_train, data=x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bb04bb7-430a-4eb4-bf61-9cf64e129226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flat the target data\n",
    "y_train_stack = y_train.stack(gridpoint=('x', 'y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99fdc317-4af9-4b68-b6b8-b41cdb721cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the loss function\n",
    "loss_function = deep4downscaling.deep.loss.MseLoss(ignore_nans=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ceb3e96-b461-4afa-9d41-f427cf64ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to numpy arrays\n",
    "x_train_stand_arr = deep4downscaling.trans.xarray_to_numpy(x_train_stand)\n",
    "y_train_arr = deep4downscaling.trans.xarray_to_numpy(y_train_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09aa51b2-ec91-4f20-83a7-b3f4243206a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "train_dataset = deep4downscaling.deep.utils.StandardDataset(x=x_train_stand_arr,\n",
    "                                                            y=y_train_arr)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_dataset, valid_dataset = random_split(train_dataset,\n",
    "                                            [0.9, 0.1])\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size,\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d115aa88-1fff-4afc-abc5-a9528996c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model\n",
    "model_name = f'DeepESD_{training_experiment}_{target_var}'\n",
    "model = deep4downscaling.deep.models.DeepESDpr(x_shape=x_train_stand_arr.shape,\n",
    "                                               y_shape=y_train_arr.shape,\n",
    "                                               filters_last_conv=1,\n",
    "                                               stochastic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "838aa521-af2a-4ce7-8531-42b170074d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some hyperparameters\n",
    "num_epochs = 10000\n",
    "patience_early_stopping = 20\n",
    "\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "494b4c50-d7fa-4f5d-869d-845a47118c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training device\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3c9327b-2aca-4b53-9793-1e30bae6ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_loss, val_loss = deep4downscaling.deep.train.standard_training_loop(\n",
    "                            model=model, model_name=model_name, model_path=MODELS_PATH,\n",
    "                            device=device, num_epochs=num_epochs,\n",
    "                            loss_function=loss_function, optimizer=optimizer,\n",
    "                            train_data=train_dataloader, valid_data=valid_dataloader,\n",
    "                            patience_early_stopping=patience_early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1493b32c-73f1-480b-9243-717319b54bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model weights into the DeepESD architecture\n",
    "model.load_state_dict(torch.load(f'{MODELS_PATH}/{model_name}.pt'))\n",
    "\n",
    "# Standardize the test data\n",
    "x_test_stand = deep4downscaling.trans.standardize(data_ref=x_train, data=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6090fc56-20c2-4933-8c9e-c1551d8cd321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mask to unflat the prediction\n",
    "y_mask = xr.ones_like(y_train.isel(time=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "461781c1-0b87-4b12-8069-5da062b31486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions\n",
    "pred_test = deep4downscaling.deep.pred.compute_preds_standard(\n",
    "                                x_data=x_test_stand, model=model,\n",
    "                                device=device, var_target=target_var,\n",
    "                                mask=y_mask, batch_size=16,\n",
    "                                spatial_dims=('x', 'y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5187291-2fce-4d27-ab65-7a9e8e80b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predictions\n",
    "deep4downscaling.viz.simple_map_plot(data=pred_test.mean('time'),\n",
    "                                     colorbar='hot_r', var_to_plot=target_var,\n",
    "                                     output_path=f'./{FIGURES_PATH}/prediction_test_mean_{training_experiment}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "322dd949-0f99-44dc-9f96-a2635bd20d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform some evaluation\n",
    "bias_mean = deep4downscaling.metrics.bias_mean(target=y_test, pred=pred_test,\n",
    "                                               var_target=target_var) \n",
    "\n",
    "bias_p02 = deep4downscaling.metrics.bias_quantile(target=y_test, pred=pred_test,\n",
    "                                                  quantile=0.02, var_target=target_var)\n",
    "\n",
    "bias_p98 = deep4downscaling.metrics.bias_quantile(target=y_test, pred=pred_test,\n",
    "                                                  quantile=0.98, var_target=target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb0c9d3a-f0dd-4aff-b7e0-d11f7a873599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "deep4downscaling.viz.simple_map_plot(data=bias_mean, var_to_plot=target_var,\n",
    "                                     colorbar='RdBu_r', vlimits=(-2, 2),\n",
    "                                     output_path=f'./{FIGURES_PATH}/bias_mean_test_{training_experiment}.pdf')\n",
    "\n",
    "deep4downscaling.viz.simple_map_plot(data=bias_p02, var_to_plot=target_var,\n",
    "                                     colorbar='RdBu_r', vlimits=(-2, 2),\n",
    "                                     output_path=f'./{FIGURES_PATH}/bias_p02_test_{training_experiment}.pdf')\n",
    "\n",
    "deep4downscaling.viz.simple_map_plot(data=bias_p98, var_to_plot=target_var,\n",
    "                                     colorbar='RdBu_r', vlimits=(-2, 2),\n",
    "                                     output_path=f'./{FIGURES_PATH}/bias_p98_test_{training_experiment}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d12f33-0443-49a6-b569-12fab370afdb",
   "metadata": {},
   "source": [
    "### Evaluation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4bbd4af-106c-4ea8-b966-751a7dc38eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the experiment for training the model\n",
    "evaluation_experiment = 'mid_century' # (historical, mid_century, end_century)\n",
    "mode = 'imperfect' # (imperfect, perfect)\n",
    "gcm_name = 'MPI-ESM-LR' # (CNRM-CM5, MPI-ESM-LR)\n",
    "\n",
    "# Set the period\n",
    "if evaluation_experiment == 'historical':\n",
    "    period_evaluation = '1981-2000'\n",
    "elif evaluation_experiment == 'mid_century':\n",
    "    period_evaluation = '2041-2060'\n",
    "elif evaluation_experiment == 'end_century':\n",
    "    period_evaluation = '2080-2099'\n",
    "else:\n",
    "    raise ValueError('Provide a valid date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82e6143f-649a-41f5-8201-5b88e40f496e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 112MB\n",
      "Dimensions:  (time: 7305, lat: 16, lon: 16)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 58kB 2041-01-01T12:00:00 ... 2060-12-31T12...\n",
      "  * lat      (lat) float64 128B 32.0 34.0 36.0 38.0 40.0 ... 56.0 58.0 60.0 62.0\n",
      "  * lon      (lon) float64 128B -4.0 -2.0 0.0 2.0 4.0 ... 20.0 22.0 24.0 26.0\n",
      "Data variables: (12/15)\n",
      "    u_850    (time, lat, lon) float32 7MB ...\n",
      "    u_700    (time, lat, lon) float32 7MB ...\n",
      "    u_500    (time, lat, lon) float32 7MB ...\n",
      "    v_850    (time, lat, lon) float32 7MB ...\n",
      "    v_700    (time, lat, lon) float32 7MB ...\n",
      "    v_500    (time, lat, lon) float32 7MB ...\n",
      "    ...       ...\n",
      "    z_850    (time, lat, lon) float32 7MB ...\n",
      "    z_700    (time, lat, lon) float32 7MB ...\n",
      "    z_500    (time, lat, lon) float32 7MB ...\n",
      "    q_850    (time, lat, lon) float32 7MB ...\n",
      "    q_700    (time, lat, lon) float32 7MB ...\n",
      "    q_500    (time, lat, lon) float32 7MB ...\n",
      "Attributes:\n",
      "    regrid_method:  conservative\n"
     ]
    }
   ],
   "source": [
    "# Load predictors\n",
    "predictor_evaluation_filename = f'{DATA_PATH}/test/{evaluation_experiment}/predictors/{mode}/{gcm_name}_{period_evaluation}.nc'\n",
    "predictor_evaluation = xr.open_dataset(predictor_evaluation_filename)\n",
    "print(predictor_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d622fabe-5b8d-4502-94ab-0ce00e48fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the predictor\n",
    "predictor_evaluation_stand = deep4downscaling.trans.standardize(data_ref=x_train, data=predictor_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d67077a4-8c01-4fcb-ba39-94cba1655391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions\n",
    "pred_evaluation = deep4downscaling.deep.pred.compute_preds_standard(\n",
    "                                    x_data=predictor_evaluation_stand, model=model,\n",
    "                                    device=device, var_target=target_var,\n",
    "                                    mask=y_mask, batch_size=16,\n",
    "                                    spatial_dims=('x', 'y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d5430a2-50ab-4bc7-93ff-4dc46f0d3701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the climatology\n",
    "deep4downscaling.viz.simple_map_plot(data=pred_evaluation.mean('time'), var_to_plot=target_var,\n",
    "                                     colorbar='hot_r', vlimits=(270, 310),\n",
    "                                     output_path=f'./{FIGURES_PATH}/climatology_predictand_{evaluation_experiment}_{gcm_name}_{mode}.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
